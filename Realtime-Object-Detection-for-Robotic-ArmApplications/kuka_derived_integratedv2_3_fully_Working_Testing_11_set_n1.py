import pybullet as p
import time
import datetime
import pybullet_data
import os
import numpy as np
import copy
import math
import random
from kuka_original import Kuka
import os
os.environ["CUDA_VISIBLE_DEVICES"]="0"
import matplotlib.pyplot as plt
import time
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import msvcrt
from multiprocessing import Process
import deepq2
from deepq2 import MyModel
from deepq2 import DQN
import cv2
physical_devices = tf.config.list_physical_devices('GPU')
try:
  tf.config.experimental.set_memory_growth(physical_devices[0], True)
except:
  # Invalid device or cannot modify virtual devices once initialized.
  pass

from detecto import core, utils, visualize
global model
model = core.Model()
##############################
from buffer import ReplayBuffer
x = datetime.datetime.now()
writer = tf.summary.create_file_writer(f"tmp/log/{x.day}_{x.month}_{x.year}  {x.hour }.{x.minute }")
#################
cid = p.connect(p.SHARED_MEMORY)
if (cid < 0):
  p.connect(p.GUI)
p.setAdditionalSearchPath(pybullet_data.getDataPath())
p.resetSimulation()
############################## Kuka class predefined
############ ### crentre set at base of kuka
############################################## in deepq1 set n = 1
def basicEnv():
  kuka = Kuka()
  shift = [1.3, -0.7, 0.75] ## when camera feed viewd from top
  shift[0] = shift[0] - 0.7 # forward backward
  shift[1] = shift[1] + 0.6 # left right
  shift[2] = shift[2] - 0.15 # up down
  plane = p.loadURDF("plane.urdf"       , 0.000000 - shift[0],  0.000000 - shift[1], 0.000000 - shift[2], 0.000000, 0.000000, 0.000000, 1.000000)
  table = p.loadURDF("table/table.urdf" , 0.900000 - shift[0], -0.200000 - shift[1], 0.000000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107)
  tray =p.loadURDF("tray/tray.urdf"   , 1.070000 - shift[0],  -0.200000 - shift[1], 0.52500000 - shift[2], 0.000000, 0.000000, 0.000000, -1.000000)
  objectList = []
  return kuka , plane , table , tray,objectList,shift

def reset(shift,kuka,obj_plane,obj_tray,obj_table,*obj):
  p.resetSimulation()
  kuka = Kuka()
  kukaBasePosAndOrn = [-0.100000, 0.000000, 0.070000 , 0.000000, 0.000000, 0.000000, 1.000000]
  gravityAbs = 9.810000

  obj_plane = p.loadURDF("plane.urdf"       , 0.000000 - shift[0],  0.000000 - shift[1], 0.000000 - shift[2], 0.000000, 0.000000, 0.000000, 1.000000)

  obj_table = p.loadURDF("table/table.urdf" , 0.900000 - shift[0], -0.200000 - shift[1], 0.000000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107)

  obj_tray = p.loadURDF("tray/tray.urdf"   , 1.070000 - shift[0],  -0.200000 - shift[1], 0.52500000 - shift[2], 0.000000, 0.000000, 0.000000, -1.000000)
  a = 0.2*(np.random.rand(3)-0.5)
  obj = []
  #-1
  #obj.append(p.loadURDF("duck_vhacd.urdf"  , 1.300000 - shift[0],  0.300000 - shift[1], 0.900000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  obj.append(p.loadURDF("duck_vhacd.urdf"  , 1.160000 + a[0]- shift[0], -0.200000 + a[1] - shift[1], 0.6200000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #jenga.urdf"  , 1.160000 + a[0]- shift[0], -0.200000 + a[1] - shift[1], 0.6200000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #obj.append(p.loadURDF("sphere_small.urdf"  , 1.160000 + a[0]- shift[0], -0.200000 + a[1] - shift[1], 0.6200000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #obj.append(p.loadURDF("teddy_vhacd.urdf"  , 1.050000 + a[0]- shift[0], -0.200000 + a[1] - shift[1], 0.650000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107)) 
  #obj.append(p.loadURDF("jenga/jenga.urdf" , 1.300000 - shift[0], -0.700000 - shift[1], 1.750000 - shift[2], 0.000000, 0.707107, 0.000000, 0.707107))
  #obj.append(p.loadURDF("jenga/jenga.urdf" , 1.200000 - shift[0], -0.700000 - shift[1], 0.750000 - shift[2], 0.000000, 0.707107, 0.000000, 0.000000))
  #obj.append(p.loadURDF("jenga/jenga.urdf" , 1.100000 - shift[0], -0.700000 - shift[1], 0.750000 - shift[2], 0.000000, 0.707107, 0.000000, 0.707107))
  #obj.append(p.loadURDF("jenga/jenga.urdf" , 1.000000 - shift[0], -0.700000 - shift[1], 0.750000 - shift[2], 0.000000, 0.707107, 0.000000, 0.707107))
  #obj.append(p.loadURDF("jenga/jenga.urdf" , 0.900000 - shift[0], -0.700000 - shift[1], 0.750000 - shift[2], 0.000000, 0.707107, 0.000000, 0.707107))
  #obj.append(p.loadURDF("jenga/jenga.urdf" , 0.800000 - shift[0], -0.700000 - shift[1], 0.750000 - shift[2], 0.000000, 0.000000, 0.000000, 1.000000))
  #obj.append(p.loadURDF("teddy_vhacd.urdf" , 1.050000 - shift[0], -0.500000 - shift[1], 0.700000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #obj.append(p.loadURDF("cube_small.urdf"  , 1.050000 - shift[0], -0.500000 - shift[1], 0.700000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #obj.append(p.loadURDF("sphere_small.urdf", 0.950000 - shift[0], -0.500000 - shift[1], 0.700000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #obj.append(p.loadURDF("duck_vhacd.urdf"  , 0.950000 - shift[0], -0.400000 - shift[1], 0.900000 - shift[2], 0.000000, 0.000000, 0.707107, 0.707107))
  #obj.append(p.loadURDF("lego/lego.urdf"   , 1.000000 - shift[0], -0.500000 - shift[1], 0.900000 - shift[2], 0.000000, 0.000000, 0.000000, 1.000000))
  #obj.append(p.loadURDF("lego/lego.urdf"   , 1.000000 - shift[0], -0.500000 - shift[1], 0.700000 - shift[2], 0.000000, 0.000000, 0.000000, 1.000000))
  #obj.append(p.loadURDF("lego/lego.urdf"   , 1.000000 - shift[0], -0.500000 - shift[1], 0.800000 - shift[2], 0.000000, 0.000000, 0.000000, 1.000000))
  p.setGravity(0, 0, -gravityAbs)
  ref_time = time.time()
  state = distanceBeforeAction = distancefunc(kuka.kukaUid , obj[0],"Vect",1 ).copy()
  time.sleep(1)
  return state,kuka,obj


############## camera
def imageshape():
  width = 144
  height = 144
  return width , height
def cameraLocation(UniqueId , link , campos , shift , fixed):
  #shift == [0,0,0] for no shift
  #campos == fixed position of camera without any shift , final pos = campos - shift
  #-1 for base link
  if fixed == True:
    viewMat= p.computeViewMatrixFromYawPitchRoll(cameraTargetPosition = [0,-0.05,-0.3] , yaw = 91.20 , pitch = -37.40 , distance = 1.42 , roll = 0 , upAxisIndex = 2)
    #viewMat = p.computeViewMatrix(cameraEyePosition=[campos[0] - shift[0], campos[1] - shift[1], campos[2] - shift[2]]
                               # ,cameraTargetPosition=[campos[0] - shift[0], campos[1] - shift[1], -100 - shift[2]]
                                #,cameraUpVector=[1, 0, 0]
                                # )
  else: ### change projectionMatrix fov to 60-90 degree
    wristCam = p.getLinkState(UniqueId , link)[0]
    viewMat = p.computeViewMatrix(cameraEyePosition=wristCam
                                ,cameraTargetPosition=[wristCam[0], wristCam[1] , -100 ]
                                ,cameraUpVector=[1, 0, 0]
                                 )
  return viewMat

################# Actions 

def possibleactions(typeOfAction):
  action = [0,0,0,0,0]
  dv = 0.02#0.0015
  dv_ = dv/2
  if typeOfAction =="stop":
    action = [0,0,0,0,0]
  if typeOfAction == "left":
    action = [0,dv,-dv_,0,1.57/8]
  if typeOfAction == "right":
    action = [0,-dv,-dv_,0,1.57/8]
  if typeOfAction == "up":
    action = [0,0,dv_,0,0]
  if typeOfAction == "down":
    action = [0,0,-dv_,0,1.57/8]
  if typeOfAction == "forward":
    action = [dv,0,-dv_,0,1.57/8]
  if typeOfAction == "backward":
    action = [-dv,0,-dv_,0,1.57/8]
  if typeOfAction == "open":
    action = [0,0,0,0,1.57/8]
  #if typeOfAction == "rotate":
    #action = [0,0,0,1.57/20,0]
  return action

def actionfunc(index):
  actionList = ["stop","left" , "right" , "down" , "forward" , "backward"  , "up", "open"]
  if index<0 or index>(len(actionList)-1):
    index = 0
  return possibleactions(actionList[index])

def randomNum():
  return np.random.choice([0,1,2,3,4,5,6,7,8]) 
############
projectionMatrix = p.computeProjectionMatrixFOV(fov=45.0,aspect=1.0,nearVal=0.1,farVal=1.6)
k = 0
###########

#actionList = ["stop","left" , "right" , "up" , "down" , "forward" , "backward"  , "open",'rotate']
actionList = ["stop","left" , "right"  , "down" , "forward" , "backward"  , "up", "open"]
############
def distancefunc(uid1 , uid2,typeOfdistance,ifkuka):
  endEff = 11
  if ifkuka == 1:
    distanceEucl = np.round(abs(p.getClosestPoints(uid1 , uid2,10,endEff )[0][8]), decimals=4)
    distanceVect = np.round(np.array(p.getLinkState(uid1 , endEff )[0]) - np.array(p.getBasePositionAndOrientation(uid2)[0]), decimals=4)
    distanceManh =  abs(distanceVect[0] ) + abs(distanceVect[1] ) #+ abs(distanceVect[2] )
    distanceEucl2 =  np.sqrt(abs(distanceVect[0] )**2 + abs(distanceVect[1] ) **2)
    distance = distanceManh.copy()
  else:
    distanceEucl = np.round(abs(p.getClosestPoints(uid1 , uid2,10)[0][8]), decimals=4)
    distanceVect = np.round(np.array(p.getBasePositionAndOrientation(uid1)[0] - np.array(p.getBasePositionAndOrientation(uid2)[0])), decimals=4)
    distanceManh =  abs(distanceVect[0] ) + abs(distanceVect[1] ) #+ abs(distanceVect[2] )
    distanceEucl2 =  np.sqrt(abs(distanceVect[0] )**2 + abs(distanceVect[1] ) **2)
    distance = distanceManh.copy()
  if typeOfdistance=="Vect":
    return  distanceVect
  if typeOfdistance=="Manh":
    return distanceManh
  if typeOfdistance=="Eucl2":
    return distanceEucl2 
  else:
    return distanceEucl
  
def Env(kuka,possibleAction,obj):
  viewMatrix = cameraLocation(kuka.kukaUid , 7 , [1.00,-0.20 , 2.20] , shift , True)
  distanceBeforeAction = distancefunc(kuka.kukaUid , obj[0],"Vect",1 ).copy()
  d1 = distancefunc(kuka.kukaUid , obj[0],"Eucl2",1 ).copy()
  kuka.applyAction(possibleAction)
  __, _, rgbImg, depthImg, segImg = p.getCameraImage(width=imageshape()[0], height=imageshape()[1], viewMatrix=viewMatrix,projectionMatrix=projectionMatrix) ##camera feed
  state = np.array(rgbImg)
  #state_tensor = tf.convert_to_tensor(state)
  #state_tensor = tf.expand_dims(state_tensor, 0)
  p.setRealTimeSimulation(1)
  distanceAfterAction = distancefunc(kuka.kukaUid , obj[0] ,"Vect",1)
  d2 = distancefunc(kuka.kukaUid , obj[0],"Eucl2" ,1).copy()
  distance = np.absolute(np.round(distanceAfterAction - distanceBeforeAction,decimals=4))
  #p.getBasePositionAndOrientation()
  obj_table_dist = distancefunc(obj[0] ,obj_table,'Vect',0)[2]
  #print(f"distance++++++++++++++++++{obj_table_dist}")
  reward = 0
  done = 0
  #print(rgbImg[:,:,:3].shape)
  predict = rgbImg[:,:,:3]
  labels, boxes, scores = model.predict_top(predict)
  if len(boxes)>0:
    x1y1 = [boxes[0][0] , boxes[0][1]]
    x2y2 = [boxes[0][2] , boxes[0][3]]
    print(labels)
    #predict  = cv2.rectangle(predict , x1y1, x2y2, (1,0,0), 2)
  #cv2.imshow("img",predict )
  #if cv2.waitKey(1) & 0xFF == ord('q'):
    print("lol")#break 
  #if d2<0.01: #0.004 for endeff 13
    #done = 0 #1 print("by distance")    
  #elif (d2<0.1)*(obj_table_dist >0.4):
    #done = 1  print("by lift")
  if d2<d1:
    reward = 0.01 + np.exp(-d2)/1000
  elif obj_table_dist>0.3:
    reward =  1
    done = 1
    print("lifted")
  elif d2>d1:
    reward = -0.01 #- np.exp(-d2)/1000
    done = 0
  else:
    reward = 0
    
  #if d2<d1:
    #reward = 1 + (obj_table_dist-0.019)*(d2<0.1)*(obj_table_dist>0.019)*30 + 10*(len(p.getContactPoints(kuka.kukaUid , obj[0] )) != 0)#+ 2*np.exp(-d2) 
    #if d2<0.1:
      #reward = reward  + np.exp(obj_table_dist-0.016)
  
  #elif d2>=d1:
    #reward = -1 -(obj_table_dist<0.019)
  #else:
    #reward = 0.1
  #reward = reward/10 
  #print(f"done::{done} reward::{reward} ")
  return distanceBeforeAction  , reward , distanceAfterAction ,done,  predict
#####################
max_length = 1000000
input_shape =  3
n_actions = 6
hiddenUnits_Sizes = [32,32]

gamma = 0.99
max_xp = 10000
min_xp = 201
batch_size = 32
lr = 0.0001
epsilon = 0.99
min_epsilon = 0.1
decay= 0.9995
update_Q_steps= 1000

losses = list()
reward_s = 0
done = 0

#memory = ReplayBuffer(max_length ,input_shape ,n_actions ) ######## check buffer.py
####################
Q = DQN(input_shape , n_actions ,  hiddenUnits_Sizes , gamma ,max_xp ,min_xp , batch_size , lr)
Q.model.load_weights("tmp/log/checkpoint/cp-best1.ckpt")
#Q_= DQN(input_shape , n_actions ,  hiddenUnits_Sizes , gamma ,max_xp ,min_xp , batch_size , lr)
####################
kuka,obj_plane,obj_tray,obj_table,obj,shift = basicEnv()
state, kuka , obj = reset(shift , kuka,obj_plane,obj_tray,obj_table,*obj)
initial_pos = kuka.endEffectorPos.copy()
ep_reward = 0
ep = 0
#################################
iter = 0
action = 2
while(1):
  #position = np.array(kuka.endEffectorPos) - np.array(initial_pos)
  action = Q.get_action(state, 0)
  state , reward , state_,done ,img= Env(kuka,actionfunc(action),obj)

  #print(action)
  if iter%40 == 39:
    done = 1
    for k in range(50):
      Env(kuka,actionfunc(6),obj)
      #print("up")
    #ep_reward = 0
  if done:
    #reward = -reward_s #-200
    ep +=1
    state,kuka,obj = reset(shift,kuka,obj_plane,obj_tray,obj_table,*obj)
    ep_reward += reward
    
  #xp = {'s': state, 'a': action, 'r': reward, 's2': state_, 'done': done}
  #Q.add_experience(xp)
  #loss = Q.train(Q_)
  #reward_s += reward
  
  #if isinstance(loss, int):
    #losses.append(loss)
  #else:
    #losses.append(loss.numpy())
  iter+=1
  #if iter%update_Q_steps== 0:
    #Q.copy_weights(Q)
    
  #print(f"                            meanLoss ==  {np.mean(losses)}           rewards == {reward_s}")
  #epsilon = max(epsilon*decay , min_epsilon)
  #with writer.as_default():
    #tf.summary.scalar('episode reward', reward_s, step=iter)
    #tf.summary.scalar('running avg reward(100)', avg_rewards, step=n)
    #tf.summary.scalar('average loss)', loss, step=iter)
    #tf.summary.scalar('episodes)', ep, step=iter)
    #if iter% 100 == 0:
      #print("episode:",ep , "episode reward:", ep_reward, "eps:", epsilon, 
        #          "episode loss: ", loss)
  #print("avg reward for last 100 episodes:", avg_rewards)
  #sample = memory.sample_buffer(10)
#################
p.disconnect()
